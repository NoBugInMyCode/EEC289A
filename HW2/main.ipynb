{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "The following code blocks is the reproduced Efros & Leung 1999 algorithm with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "def make_gaussian_kernel(size, sigma, device):\n",
    "    ax = torch.arange(size, device=device) - size // 2\n",
    "    xx, yy = torch.meshgrid(ax, ax, indexing='ij')\n",
    "    kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    return kernel / kernel.sum()\n",
    "\n",
    "def extract_patches_torch(sample_tensor, window_size):\n",
    "    \"\"\"Extract RGB patches as batched tensor from [3, H, W].\"\"\"\n",
    "    C, H, W = sample_tensor.shape\n",
    "    patches = sample_tensor.unfold(1, window_size, 1).unfold(2, window_size, 1)\n",
    "    patches = patches.permute(1, 2, 0, 3, 4).contiguous().view(-1, C, window_size, window_size)\n",
    "\n",
    "    half_w = window_size // 2\n",
    "    centers = sample_tensor[:, half_w:H-half_w, half_w:W-half_w].permute(1, 2, 0).reshape(-1, C)\n",
    "    return patches, centers\n",
    "\n",
    "def count_known_neighbors(mask, y, x, window_size):\n",
    "    y_start = max(0, y - window_size//2)\n",
    "    y_end = min(mask.shape[0], y + window_size//2 + 1)\n",
    "    x_start = max(0, x - window_size//2)\n",
    "    x_end = min(mask.shape[1], x + window_size//2 + 1)\n",
    "    return mask[y_start:y_end, x_start:x_end].sum().item()\n",
    "\n",
    "def efros_leung_synthesis_cuda(sample_patches, sample_centers, out_size=128,\n",
    "                              window_size=11, seed_size=3, device='cuda'):\n",
    "    \"\"\"Efros-Leung synthesis with RGB image and CUDA acceleration.\"\"\"\n",
    "    C = 3\n",
    "    out_img = torch.zeros((C, out_size, out_size), dtype=torch.float32, device=device)\n",
    "    synthesized = torch.zeros((out_size, out_size), dtype=torch.bool, device=device)\n",
    "\n",
    "    # Seed\n",
    "    seed_y = torch.randint(0, out_size - seed_size, (1,)).item()\n",
    "    seed_x = torch.randint(0, out_size - seed_size, (1,)).item()\n",
    "    out_img[:, seed_y:seed_y+seed_size, seed_x:seed_x+seed_size] = 0.5\n",
    "    synthesized[seed_y:seed_y+seed_size, seed_x:seed_x+seed_size] = True\n",
    "\n",
    "    # Gaussian kernel\n",
    "    gaussian = make_gaussian_kernel(window_size, sigma=window_size//6, device=device)\n",
    "    gaussian = gaussian.unsqueeze(0).expand(C, -1, -1)  # [3, w, w]\n",
    "\n",
    "    # Prepare patch database\n",
    "    sample_patches = sample_patches.to(device)\n",
    "    sample_centers = sample_centers.to(device)\n",
    "\n",
    "    half_w = window_size // 2\n",
    "    q = []\n",
    "    for y in range(seed_y, seed_y + seed_size):\n",
    "        for x in range(seed_x, seed_x + seed_size):\n",
    "            for dy, dx in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < out_size and 0 <= nx < out_size and not synthesized[ny, nx]:\n",
    "                    heapq.heappush(q, (-count_known_neighbors(synthesized, ny, nx, window_size), (ny, nx)))\n",
    "\n",
    "    progress = tqdm(total=out_size*out_size - seed_size**2)\n",
    "    while q:\n",
    "        _, (y, x) = heapq.heappop(q)\n",
    "        if synthesized[y, x]:\n",
    "            continue\n",
    "\n",
    "        y_start = max(0, y - half_w)\n",
    "        y_end = min(out_size, y + half_w + 1)\n",
    "        x_start = max(0, x - half_w)\n",
    "        x_end = min(out_size, x + half_w + 1)\n",
    "\n",
    "        window = out_img[:, y_start:y_end, x_start:x_end]\n",
    "        mask = synthesized[y_start:y_end, x_start:x_end].float()\n",
    "\n",
    "        pad_top = half_w - (y - y_start)\n",
    "        pad_bottom = half_w - (y_end - y - 1)\n",
    "        pad_left = half_w - (x - x_start)\n",
    "        pad_right = half_w - (x_end - x - 1)\n",
    "\n",
    "        window = torch.nn.functional.pad(window, (pad_left, pad_right, pad_top, pad_bottom))\n",
    "        mask = torch.nn.functional.pad(mask, (pad_left, pad_right, pad_top, pad_bottom))\n",
    "        mask = mask.unsqueeze(0).expand_as(window)\n",
    "\n",
    "        diff = (sample_patches - window.unsqueeze(0)) * mask.unsqueeze(0)\n",
    "        errors = ((diff ** 2) * gaussian).sum(dim=(1, 2, 3)) / mask.sum()\n",
    "\n",
    "        min_error = errors.min()\n",
    "        valid = errors <= min_error * 1.2\n",
    "        candidates = sample_centers[valid]\n",
    "\n",
    "        if len(candidates) > 0:\n",
    "            out_img[:, y, x] = candidates[torch.randint(len(candidates), (1,))]\n",
    "            synthesized[y, x] = True\n",
    "            progress.update(1)\n",
    "\n",
    "            for dy, dx in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < out_size and 0 <= nx < out_size and not synthesized[ny, nx]:\n",
    "                    heapq.heappush(q, (-count_known_neighbors(synthesized, ny, nx, window_size), (ny, nx)))\n",
    "\n",
    "    progress.close()\n",
    "    return (out_img.clamp(0,1) * 255).byte().permute(1, 2, 0).cpu().numpy()  # [H, W, 3]\n",
    "\n",
    "def efros_leung_synthesis_with_one_image(image_path, out_size, window_size):\n",
    "    # Load RGB sample image\n",
    "    sample = cv2.imread(image_path)  # BGR to RGB\n",
    "    sample = torch.tensor(sample, dtype=torch.float32, device='cuda').permute(2, 0, 1) / 255.0  # [3, H, W]\n",
    "\n",
    "    # Extract patches\n",
    "    window_size = 11\n",
    "    patches, centers = extract_patches_torch(sample, window_size)\n",
    "\n",
    "    # Synthesize\n",
    "    synthesized = efros_leung_synthesis_cuda(\n",
    "        patches, centers,\n",
    "        out_size=out_size,\n",
    "        window_size=window_size\n",
    "    )\n",
    "\n",
    "    return synthesized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: regular textures\n",
    "Regular textures refers to images composed of repeated, nearly identical texels (texture elements) arranged in a structured pattern. The examples are brick walls, grides, tiles, and checkboards.\n",
    "\n",
    "In the first experiment, given twelve 530×530 regular textures, apply the algorithm to synthesize new texture images of larger size (e.g., 1024×1024) that visually preserve the structural and statistical properties of the original textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7618/1048567 [01:33<4:45:53, 60.68it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m synthesized_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output/regular_textures/synthesized_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m synthesized \u001b[38;5;241m=\u001b[39m \u001b[43mefros_leung_synthesis_with_one_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(synthesized_path, synthesized)\n",
      "Cell \u001b[0;32mIn[8], line 113\u001b[0m, in \u001b[0;36mefros_leung_synthesis_with_one_image\u001b[0;34m(image_path, out_size, window_size)\u001b[0m\n\u001b[1;32m    110\u001b[0m patches, centers \u001b[38;5;241m=\u001b[39m extract_patches_torch(sample, window_size)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Synthesize\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m synthesized \u001b[38;5;241m=\u001b[39m \u001b[43mefros_leung_synthesis_cuda\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m synthesized\n",
      "Cell \u001b[0;32mIn[8], line 98\u001b[0m, in \u001b[0;36mefros_leung_synthesis_cuda\u001b[0;34m(sample_patches, sample_centers, out_size, window_size, seed_size, device)\u001b[0m\n\u001b[1;32m     96\u001b[0m             ny, nx \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m dy, x \u001b[38;5;241m+\u001b[39m dx\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m ny \u001b[38;5;241m<\u001b[39m out_size \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m nx \u001b[38;5;241m<\u001b[39m out_size \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m synthesized[ny, nx]:\n\u001b[0;32m---> 98\u001b[0m                 heapq\u001b[38;5;241m.\u001b[39mheappush(q, (\u001b[38;5;241m-\u001b[39m\u001b[43mcount_known_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msynthesized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mny\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m, (ny, nx)))\n\u001b[1;32m    100\u001b[0m progress\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (out_img\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mbyte()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m, in \u001b[0;36mcount_known_neighbors\u001b[0;34m(mask, y, x, window_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m x_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, x \u001b[38;5;241m-\u001b[39m window_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     27\u001b[0m x_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x \u001b[38;5;241m+\u001b[39m window_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_end\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load sample texture\n",
    "for image_id in range(1, 3):\n",
    "    image_path = f'./images/{image_id}.png'\n",
    "    synthesized_path = f'./output/regular_textures/synthesized_{image_id}.png'\n",
    "    synthesized = efros_leung_synthesis_with_one_image(image_path=image_path, out_size=1024, window_size=7)\n",
    "    cv2.imwrite(synthesized_path, synthesized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "289a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
