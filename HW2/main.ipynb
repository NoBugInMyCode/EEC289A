{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "The following code blocks is the reproduced Efros & Leung 1999 algorithm with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "def make_gaussian_kernel(size, sigma, device):\n",
    "    ax = torch.arange(size, device=device) - size // 2\n",
    "    xx, yy = torch.meshgrid(ax, ax, indexing='ij')\n",
    "    kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    return kernel / kernel.sum()\n",
    "\n",
    "def extract_patches_torch(sample_tensor, window_size):\n",
    "    \"\"\"Extract RGB patches as batched tensor from [3, H, W].\"\"\"\n",
    "    C, H, W = sample_tensor.shape\n",
    "    patches = sample_tensor.unfold(1, window_size, 1).unfold(2, window_size, 1)\n",
    "    patches = patches.permute(1, 2, 0, 3, 4).contiguous().view(-1, C, window_size, window_size)\n",
    "\n",
    "    half_w = window_size // 2\n",
    "    centers = sample_tensor[:, half_w:H-half_w, half_w:W-half_w].permute(1, 2, 0).reshape(-1, C)\n",
    "    return patches, centers\n",
    "\n",
    "def count_known_neighbors(mask, y, x, window_size):\n",
    "    y_start = max(0, y - window_size//2)\n",
    "    y_end = min(mask.shape[0], y + window_size//2 + 1)\n",
    "    x_start = max(0, x - window_size//2)\n",
    "    x_end = min(mask.shape[1], x + window_size//2 + 1)\n",
    "    return mask[y_start:y_end, x_start:x_end].sum().item()\n",
    "\n",
    "def efros_leung_synthesis_cuda(sample_patches, sample_centers, out_size=128,\n",
    "                              window_size=11, seed_size=3, device='cuda'):\n",
    "    \"\"\"Efros-Leung synthesis with RGB image and CUDA acceleration.\"\"\"\n",
    "    C = 3\n",
    "    out_img = torch.zeros((C, out_size, out_size), dtype=torch.float32, device=device)\n",
    "    synthesized = torch.zeros((out_size, out_size), dtype=torch.bool, device=device)\n",
    "\n",
    "    # Seed\n",
    "    seed_y = torch.randint(0, out_size - seed_size, (1,)).item()\n",
    "    seed_x = torch.randint(0, out_size - seed_size, (1,)).item()\n",
    "    out_img[:, seed_y:seed_y+seed_size, seed_x:seed_x+seed_size] = 0.5\n",
    "    synthesized[seed_y:seed_y+seed_size, seed_x:seed_x+seed_size] = True\n",
    "\n",
    "    # Gaussian kernel\n",
    "    gaussian = make_gaussian_kernel(window_size, sigma=window_size//6, device=device)\n",
    "    gaussian = gaussian.unsqueeze(0).expand(C, -1, -1)  # [3, w, w]\n",
    "\n",
    "    # Prepare patch database\n",
    "    sample_patches = sample_patches.to(device)\n",
    "    sample_centers = sample_centers.to(device)\n",
    "\n",
    "    half_w = window_size // 2\n",
    "    q = []\n",
    "    for y in range(seed_y, seed_y + seed_size):\n",
    "        for x in range(seed_x, seed_x + seed_size):\n",
    "            for dy, dx in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < out_size and 0 <= nx < out_size and not synthesized[ny, nx]:\n",
    "                    heapq.heappush(q, (-count_known_neighbors(synthesized, ny, nx, window_size), (ny, nx)))\n",
    "\n",
    "    progress = tqdm(total=out_size*out_size - seed_size**2)\n",
    "    while q:\n",
    "        _, (y, x) = heapq.heappop(q)\n",
    "        if synthesized[y, x]:\n",
    "            continue\n",
    "\n",
    "        y_start = max(0, y - half_w)\n",
    "        y_end = min(out_size, y + half_w + 1)\n",
    "        x_start = max(0, x - half_w)\n",
    "        x_end = min(out_size, x + half_w + 1)\n",
    "\n",
    "        window = out_img[:, y_start:y_end, x_start:x_end]\n",
    "        mask = synthesized[y_start:y_end, x_start:x_end].float()\n",
    "\n",
    "        pad_top = half_w - (y - y_start)\n",
    "        pad_bottom = half_w - (y_end - y - 1)\n",
    "        pad_left = half_w - (x - x_start)\n",
    "        pad_right = half_w - (x_end - x - 1)\n",
    "\n",
    "        window = torch.nn.functional.pad(window, (pad_left, pad_right, pad_top, pad_bottom))\n",
    "        mask = torch.nn.functional.pad(mask, (pad_left, pad_right, pad_top, pad_bottom))\n",
    "        mask = mask.unsqueeze(0).expand_as(window)\n",
    "\n",
    "        diff = (sample_patches - window.unsqueeze(0)) * mask.unsqueeze(0)\n",
    "        errors = ((diff ** 2) * gaussian).sum(dim=(1, 2, 3)) / mask.sum()\n",
    "\n",
    "        min_error = errors.min()\n",
    "        valid = errors <= min_error * 1.2\n",
    "        candidates = sample_centers[valid]\n",
    "\n",
    "        if len(candidates) > 0:\n",
    "            out_img[:, y, x] = candidates[torch.randint(len(candidates), (1,))]\n",
    "            synthesized[y, x] = True\n",
    "            progress.update(1)\n",
    "\n",
    "            for dy, dx in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < out_size and 0 <= nx < out_size and not synthesized[ny, nx]:\n",
    "                    heapq.heappush(q, (-count_known_neighbors(synthesized, ny, nx, window_size), (ny, nx)))\n",
    "\n",
    "    progress.close()\n",
    "    return (out_img.clamp(0,1) * 255).byte().permute(1, 2, 0).cpu().numpy()  # [H, W, 3]\n",
    "\n",
    "def efros_leung_synthesis_with_one_image(image_path, out_size, window_size):\n",
    "    # Load RGB sample image\n",
    "    sample = cv2.imread(image_path)  # BGR to RGB\n",
    "    sample = torch.tensor(sample, dtype=torch.float32, device='cuda').permute(2, 0, 1) / 255.0  # [3, H, W]\n",
    "\n",
    "    # Extract patches\n",
    "    window_size = 11\n",
    "    patches, centers = extract_patches_torch(sample, window_size)\n",
    "\n",
    "    # Synthesize\n",
    "    synthesized = efros_leung_synthesis_cuda(\n",
    "        patches, centers,\n",
    "        out_size=out_size,\n",
    "        window_size=window_size\n",
    "    )\n",
    "\n",
    "    return synthesized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: regular textures\n",
    "Regular textures refers to images composed of repeated, nearly identical texels (texture elements) arranged in a structured pattern. The examples are brick walls, grides, tiles, and checkboards.\n",
    "\n",
    "In the first experiment, given twelve 530×530 regular textures, apply the algorithm to synthesize new texture images of larger size (e.g., 1024×1024) that visually preserve the structural and statistical properties of the original textures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# Load sample texture\n",
    "for image_id in range(1, 4):\n",
    "    image_path = f'./images/{image_id}.png'\n",
    "    synthesized_path = f'./output/regular_textures/synthesized_{image_id}.png'\n",
    "    synthesized = efros_leung_synthesis_with_one_image(image_path=image_path, out_size=1024, window_size=7)\n",
    "    cv2.imwrite(synthesized_path, synthesized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: MNIST\n",
    "Instead of use one seed image as in experiment 1, we extract image patches from the whole MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches_from_mnist(dataset, window_size=7, device='cuda', max_images=50000):\n",
    "    all_patches = []\n",
    "    all_centers = []\n",
    "    for idx in range(min(max_images, len(dataset))):\n",
    "        img, _ = dataset[idx]  # [1, 28, 28]\n",
    "        img = img.squeeze(0).to(device)  # [28, 28]\n",
    "        patches, centers = extract_patches_torch(img, window_size)\n",
    "        all_patches.append(patches)\n",
    "        all_centers.append(centers)\n",
    "    \n",
    "    all_patches = torch.cat(all_patches, dim=0)\n",
    "    all_centers = torch.cat(all_centers, dim=0)\n",
    "    return all_patches, all_centers\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "mnist_train = MNIST(root='./data', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [5, 7, 11]\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    patches, centers = extract_patches_from_mnist(mnist_train, window_size=window_size, device='cuda', max_images=1000)\n",
    "    synthesized = efros_leung_synthesis_cuda(patches, centers, out_size=128, window_size=window_size, device='cuda')\n",
    "    cv2.imwrite(f'./output/mnist/synthesized_{window_size}.png', synthesized)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "289a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
